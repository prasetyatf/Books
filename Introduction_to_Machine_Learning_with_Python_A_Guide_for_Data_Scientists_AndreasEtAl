Chapter 2: Supervised Learning
--Classification and Regression
y = Class/Categoric var -> binary classification / multiclass classification
y = Numeric
we want to build a model on the training data and then be able to make accurate predictions on new(able to generalize),-
unseen data that has the same characteristics as the training set that we used.
Overfitting = occurs when you fit a model too closely to the particularities of the training set and-
obtain a model that works well on the training set but is not able to generalize to new data.
Underfitting = Choosing too simple a model that not be able to capture all the aspects of and variability in the data,
and your model will do badly even on the training set.
--Relation of Model Complexity to Dataset Size
Never underestimate the power of more data.
the larger variety of data points your dataset contains, the more complex a model you can use without overfitting.
In the real world, you often have the ability to decide how much data to collect(but not duplicating same data points
or collecting very similiar data points), which might be more beneficial than tweaking and tuning your model. 
--Supervised ML Algorithm: Some sample Dataset
low-dimensional datasets = few features. vice versa
inspecting algorithms on low-dimensional datasets can be very instructive.
...
--Decision Tree
Essentially, they learn a hierarchy of if/else questions, leading to a decision.
the splitting process happen on tree while it devide data points into two part by a line on 2D graph.
a leaf/node on a tree means region on graph.
a metrices on tree means data points composition.
A leaf/node of the tree that contains data points that all share the same target value is called pure.
A prediction on a new data point is made by checking which region of the partition of the feature space-
the point lies in, and then predicting the majority target (or the single target in the case of pure leaves)-
in that region.(classification -> mode)
trees for regression tasks, To make a prediction, we traverse the tree based on the tests in each node and find
the leaf the new data point falls into. The output for this data point is the mean target of the training points
in this leaf.(regression -> mean)
--Controlling complexity of decision trees
building a tree means continuing until all leaves are pure leads to models that are very complex and-
highly overfit to the training data.
pure leaf means a tree 100% accurate on training set.
decision boundary focuses a lot on single outlier points that are far away from the other points in that class.
Common strategies to prevent overfitting:
pre-prunning = stopping the creation of the tree early.(can use sklearn)
post-pruning(pruning) = building the tree but then removing or collapsing nodes that contain little information.
(can't use sklearn).
--Analyzing Decision Tree
for each nodes, there is:
feature = on root node, its indicate most importance feature(check using feature importance)
samples = its shows datapoint on the region
values = metrices that contain sum of each datapoints based on class
class = dominant datapoints
--Feautures Importance
the most importance feature should be the feature of root node.
f a feature has a low feature_importance, it doesn’t mean that this feature is uninformative.-
It only means that the feature was not picked by the tree, likely because another feature encodes the same information.
--forecast: DecisionTreeRegressor vs LinaeRegression
the linear model doing well on training data and test data, while tree model only good on training data.
--Strengths, Weakness, Parameters
pre-pruning: max_depth, max_leaf_nodes, or min_samples_leaf
adventages: visualized model easily understood, simple preprocessing(no need standarization, normalization),-
work well when you have features that are on completely different scales, or a mix of binary and con‐
tinuous features.
disadventages: even with the use of pre-pruning, they tend to overfit and provide poor generalization performance.
--Ensemble of Decision Tree
Ensembles = methods that combine multiple machine learning models to create more powerful models.
Ensemble Decision tree: random forests and gradient boosted decision trees.
...
--Uncertainty Estimates from Classifiers
In high-risk applications of machine learning, it is important to detect when the system is-
uncertain and can be mistaken. ex: false negative on cancer patient can lead to serious health problem.
sklearn: decision_function and predict_proba. most models have it, many have one of them.
gbrt.decision_function(X_test).shape --> the shape of decisison funtcion model(binary classification)
...

Chapter 5: Model Evaluation & Improvement
...
Cross validation
Cross Validation = scenario of splitting dataset(multiple splitting dataset)
benefit: evading lucky/unlucky effect, knowing how sensitive our model is to the selection of the training dataset-
(acuracy range), using more fold means we able tu use portion of training set.
disadventage: computational cost.
Stratified k-fold
When data is ordered, its not wise using ordinary splitting. 
ex: data ordered = 0,0,1,1,2,2. train =0,0,1,1. test = 2,2
--More control over cros val
For most use cases, the defaults of k-fold crossvalidation for regression and stratified k-fold for classification 
work well, but there are some cases where you might want to use a different strategy.
if shuffle is true then fix the random_state
--Leave-one-out cross val
each fold is a single sample. For each split, you pick a single data point to be the test set.
not suitable for large dataset.
...
(there is many strategies actually)
Grid Search
is trying all possible combinations of the parameters of interest.
--Simple Grid Search
we tried combining parameters and select best acuracy.
--The Danger of Overfitting the Parameters and the Validation Set
we need an independent set for evaluating parameters
we have three sets: 
the training set to build the model, 
the validation (or development) set to select the parameters of the model, 
and the test set to evaluate the performance of the selected parameters.
--Grid Search With Cross Val
many people use the term cross-validation colloquially to refer to grid search with cross-validation.
code: from sklearn.model_selection import GridSearchCV(READ MORE SOON!!)

Evaluation Metrics & Scoring
...it is important to choose the right metric when selecting between models and adjusting parameters.

--Keep The End Goal In Mind
not just making a prediction but using these predictions as part of a larger decisionmaking process
business metric = Before picking a machine learning metric, you should think about the high-level goal of the application.
business impact = The consequences of choosing a particular algorithm for a machine learning application.
In the early stages of development, and for adjusting parameters, it is often infeasible-
to put models into production just for testing purposes, because of the high business or personal risks that can be involved.

--Metrics for Binary Classification
--Kinds of Error
Often, accuracy is not a good measure of predictive performance, as the number of-
mistakes we make does not contain all the information we are interested in. 
For any application, we need to ask ourselves what the consequences of these mistakes might be in the real world.
false positive / type I error: Incorrect positive prediction -> a healthy guy detected has a cancer
false negative / type II error: Incorrect negative prediction -> a guy with cancer detected as healthy guy
--Imbalanced datasets
--Confusion matrices

...
Chapter 6: Algorithm Chains and Pipelines
